---
title: "Speaking Under Stress + Developing Credibility"
author: "Sahil Deo, Christian Franz, Christopher Gandrud, and Kevin Young"
date: "31 October 2014"
output:
  ioslides_presentation:
    fig_caption: true
    logo: img/HertieLogoBasic.png
    css: css/custom.css
  beamer_presentation: default
bibliography:
    - Main.bib
---

## Research overview

Understanding how monetary policymakers' use **communication** (speeches +
press releases) to:

- respond to their **political principals**

- create **credibility**

## Developed vs. Developing

Monetary policymakers:

- **Developed**: tend to have **established**
credibility and autonomy and may be using communication to **protect** it.

- **Developing**: **trying to establish**
these qualities.

## Monetary policymaking in developed economies (US)

- What do monetary policymakers consider stressful?

    + Mandated areas?

    + Something else (e.g. housing)?

- What **non-policy tools** do they use to respond to this stress?

    + Reaching out to important interest groups?

    + What they talk about?

## Monetary policymaking in developing economies (India)

- How is monetary policy **communication credibility** created?

- What impact do central bank governor **appointments** have on communication
credibility?

## Some issues (1)

> Data (i.e. text) **availability**. Limited series of easily machine
readable texts.


## Some issues (2)

> **Integrating disparate types** of information, e.g. texts from multiple
sources, locational data, macroeconomic indicators.

## Some issues (3)

> Identifying **state changes** in complex data.

## Some issues (4)

Needing to **a priori define** features of the underlying quantities
(e.g. number of topics, minimum length of states).

## Some issues (5)

> Using **topic proportions** as **dependent variables**.

## Data availability (US Federal Reserve Project)

All (> 1100) Fed governor **speeches** from June
1996 through present are easily accessible.

Government Printing Office has House and Senate **transcripts** from 2001-2012
easily accessible. Filled in with Committee websites, so:

- House: 188 transcripts from May 1997-2012

- Senate: 144 transcripts from 2001-2012

## Data availability (US Federal Reserve Project)

Effectively, our data is limited to the late 1990s through (about) the
present.

Greatly **limits the generalisability** of our findings as this is a very
particular period of US monetary policymaking.

More work needs to be done **creating corpora** of legislative and
monetary policymaking transcripts.  

Should be **easily and freely accessible** to improve **scientific
efficiency**.

## Data Availability (Resere Bank of India Project)

All **speeches** made by central bank governors and deputy governors
930 documents (1990 to present).

All **press releases** (1990 to present).

All **news articles** mentioning the Reserve Bank of India and/or its officials
~14000 documents (2000 to present; five leading Indian English newspapers).

## Integrating disparate types of information

[FILL IN]

## Integrating disparate types of information (India)

Aim to compare **sentiments** in monetary policy communication with
sentiments in corresponding news articles.

**Key assumption**: the **difference** between measures from these two
sources will give us an indication of how credible the RBI's communication is.

- Can examine changes over time.

Is this a **valid indicator**?

## Identifying state changes

Posit that there are different "scrutiny states" (e.g. low, high).

Each month or congressional hearing is not independent. But there is some
underling scrutiny state that spans months.

How to estimate?

## Defining features a priori

Non-parametric change point methods [e.g. @Matteson2014] require **minimum
state lengths** to be determined a priori.

Topic modelling with Latent Dirichlet Allocation requires a priori
specification of **number of topics**.

## Attempts to justify assumptions

Guided by **substantive prior knowledge** + what we **learn from the
data**.

**Rule of thumb for change point**: aim for the smallest substantively
meaningful minimum sizes to avoid arbitrarily ignoring shorter clusters.

**Rule of thumb for topic modelling**: smallest number of topics without
overlap.

## Change Point in House Hearings

<img src="img/ScrutinyHouseFedCP.png" alt="House Hearings with Fed" height=500 width="600"/>

## Topic proportions from Fed Speeches

<img src="img/TopicsBasic.png" alt="Topic proportions" height=500 width="600"/>

## Defining features a priori

Nonetheless **reviewers seem to be skeptical** of methods where features of
the data need to be defined a priori.

How to overcome this skepticism?

## Showing results from regressions with proportion dependent variables

Topic proportion data is in $[0,\:1]$ or (more likely) $[0,\:1)$.

Zero-Inflated Beta Regression [e.g @ospina2010inflated] is useful in this
context.

## Showing results from Zero-Inflated Beta Regression

Beta regression and Zero-One inflated Beta regression gives **results** that
many audiences find very **confusing**.

## References
